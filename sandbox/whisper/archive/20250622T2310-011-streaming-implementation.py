#!/usr/bin/env python3
import whisper
import pyaudio
import numpy as np
import wave
import tempfile
import os
import time
import threading
import queue
from collections import deque

class StreamingTranscriber:
    def __init__(self, model_name="small", chunk_duration=3.0, overlap_duration=0.5):
        """
        ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ ï¼ˆé€£ç¶šéŒ²éŸ³ç‰ˆï¼‰
        
        Args:
            model_name: Whisperãƒ¢ãƒ‡ãƒ«å
            chunk_duration: å‡¦ç†å˜ä½ã®é•·ã•ï¼ˆç§’ï¼‰
            overlap_duration: ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã®é•·ã•ï¼ˆç§’ï¼‰
        """
        print(f"ğŸ¤– Whisperãƒ¢ãƒ‡ãƒ« '{model_name}' ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        self.model = whisper.load_model(model_name)
        print("âœ… ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")
        
        self.sample_rate = 16000
        self.chunk_size = 1024
        self.chunk_duration = chunk_duration
        self.overlap_duration = overlap_duration
        
        # ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã®è¨ˆç®—
        self.chunk_samples = int(chunk_duration * self.sample_rate)
        self.overlap_samples = int(overlap_duration * self.sample_rate)
        
        # PyAudioåˆæœŸåŒ–
        self.p = pyaudio.PyAudio()
        
        # éŸ³å£°ãƒãƒƒãƒ•ã‚¡ï¼ˆé€£ç¶šéŒ²éŸ³ç”¨ï¼‰
        self.audio_buffer = deque(maxlen=self.chunk_samples * 2)
        self.process_queue = queue.Queue()
        self.is_running = False
        
        # å‰å›ã®å‡¦ç†çµæœã‚’ä¿æŒ
        self.last_text = ""
        self.total_processed_duration = 0
        
    def continuous_recording(self):
        """é€£ç¶šéŒ²éŸ³ï¼ˆåœæ­¢ã—ãªã„ï¼‰"""
        stream = self.p.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=self.sample_rate,
            input=True,
            frames_per_buffer=self.chunk_size
        )
        
        print("\nğŸ¤ é€£ç¶šéŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã™... (Ctrl+Cã§çµ‚äº†)")
        print(f"ğŸ“Š è¨­å®š: {self.chunk_duration}ç§’ã”ã¨ã«å‡¦ç†, {self.overlap_duration}ç§’ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—")
        print("-" * 80)
        
        sample_count = 0
        last_process_time = time.time()
        
        try:
            while self.is_running:
                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚Š
                data = stream.read(self.chunk_size, exception_on_overflow=False)
                audio_chunk = np.frombuffer(data, dtype=np.int16)
                
                # ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
                self.audio_buffer.extend(audio_chunk)
                sample_count += len(audio_chunk)
                
                # chunk_durationç§’åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒæºœã¾ã£ãŸã‚‰å‡¦ç†
                if sample_count >= self.chunk_samples:
                    # ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰å¿…è¦ãªåˆ†ã‚’å–å¾—
                    current_audio = list(self.audio_buffer)[-self.chunk_samples:]
                    
                    # å‡¦ç†ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
                    self.process_queue.put({
                        'audio': np.array(current_audio),
                        'timestamp': time.time(),
                        'duration': len(current_audio) / self.sample_rate
                    })
                    
                    # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—åˆ†ã‚’æ®‹ã—ã¦ã‚«ã‚¦ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
                    sample_count = self.overlap_samples
                    
                    # é€²æ—è¡¨ç¤º
                    elapsed = time.time() - last_process_time
                    print(f"\rğŸ”„ ãƒãƒ£ãƒ³ã‚¯é€ä¿¡ (çµŒé: {elapsed:.1f}ç§’)", end="", flush=True)
                    last_process_time = time.time()
                    
        finally:
            stream.stop_stream()
            stream.close()
    
    def save_audio_array(self, audio_array):
        """numpyé…åˆ—ã‚’ä¸€æ™‚WAVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_filename = tmp_file.name
            
        with wave.open(tmp_filename, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)  # 16-bit
            wf.setframerate(self.sample_rate)
            wf.writeframes(audio_array.astype(np.int16).tobytes())
            
        return tmp_filename
    
    def process_audio_chunks(self):
        """éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†"""
        while self.is_running or not self.process_queue.empty():
            try:
                # ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—
                chunk_data = self.process_queue.get(timeout=1)
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                audio_file = self.save_audio_array(chunk_data['audio'])
                
                try:
                    # æ–‡å­—èµ·ã“ã—
                    start_time = time.time()
                    result = self.model.transcribe(
                        audio_file, 
                        language="ja", 
                        fp16=False,
                        initial_prompt=self.last_text[-100:] if self.last_text else None  # å‰ã®æ–‡è„ˆã‚’ãƒ’ãƒ³ãƒˆã¨ã—ã¦æä¾›
                    )
                    transcribe_time = time.time() - start_time
                    
                    # çµæœå‡¦ç†
                    text = result["text"].strip()
                    if text:
                        # é‡è¤‡éƒ¨åˆ†ã‚’æ¤œå‡ºã—ã¦é™¤å»ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                        if self.last_text and len(self.last_text) > 10:
                            # å‰å›ã®æœ€å¾Œã®éƒ¨åˆ†ã¨ä»Šå›ã®æœ€åˆãŒé‡è¤‡ã—ã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
                            overlap_text = self._find_overlap(self.last_text, text)
                            if overlap_text:
                                text = text[len(overlap_text):]
                        
                        if text:  # é‡è¤‡é™¤å»å¾Œã‚‚ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆ
                            print(f"\nğŸ“ [{self.total_processed_duration:.1f}s-{self.total_processed_duration + chunk_data['duration']:.1f}s] {text}")
                            print(f"   (å‡¦ç†æ™‚é–“: {transcribe_time:.1f}ç§’)")
                            self.last_text = text
                        
                        self.total_processed_duration += chunk_data['duration'] - self.overlap_duration
                        
                except Exception as e:
                    print(f"\nâŒ èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
                finally:
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
                    if os.path.exists(audio_file):
                        os.unlink(audio_file)
                        
            except queue.Empty:
                continue
            except Exception as e:
                if self.is_running:
                    print(f"\nå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _find_overlap(self, text1, text2, min_overlap=5):
        """2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã®é‡è¤‡éƒ¨åˆ†ã‚’æ¤œå‡º"""
        for i in range(min(len(text1), len(text2), 20), min_overlap - 1, -1):
            if text1[-i:] == text2[:i]:
                return text2[:i]
        return ""
    
    def run(self):
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜ã‚’é–‹å§‹"""
        self.is_running = True
        
        # éŒ²éŸ³ã‚¹ãƒ¬ãƒƒãƒ‰
        record_thread = threading.Thread(target=self.continuous_recording)
        record_thread.daemon = True
        record_thread.start()
        
        # å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰
        process_thread = threading.Thread(target=self.process_audio_chunks)
        process_thread.daemon = True
        process_thread.start()
        
        try:
            while True:
                time.sleep(0.1)
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ çµ‚äº†ä¸­...")
            self.is_running = False
            
            # ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚’å¾…ã¤
            record_thread.join(timeout=2)
            process_thread.join(timeout=5)
            
            print("âœ… çµ‚äº†ã—ã¾ã—ãŸ")
            
        finally:
            self.p.terminate()

def main():
    print("=== Whisper ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°èªè­˜ ===")
    print("é€£ç¶šéŒ²éŸ³ã—ãªãŒã‚‰å®šæœŸçš„ã«èªè­˜çµæœã‚’è¡¨ç¤ºã—ã¾ã™")
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    model_name = "small"
    chunk_duration = 3.0  # 3ç§’ã”ã¨ã«å‡¦ç†
    overlap_duration = 0.5  # 0.5ç§’ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—
    
    print(f"\nè¨­å®š:")
    print(f"- ãƒ¢ãƒ‡ãƒ«: {model_name}")
    print(f"- å‡¦ç†é–“éš”: {chunk_duration}ç§’")
    print(f"- ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—: {overlap_duration}ç§’")
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜ã‚’é–‹å§‹
    transcriber = StreamingTranscriber(
        model_name=model_name,
        chunk_duration=chunk_duration,
        overlap_duration=overlap_duration
    )
    
    transcriber.run()

if __name__ == "__main__":
    main()