#!/usr/bin/env python3
import whisper
import pyaudio
import numpy as np
import wave
import tempfile
import os
import time
import threading
import queue
import multiprocessing as mp
from collections import deque
from dataclasses import dataclass
from typing import List, Tuple, Optional

@dataclass
class AudioChunk:
    """éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    audio: np.ndarray
    timestamp: float
    duration: float
    level: str  # 'short', 'medium', 'long'

class MultiLevelBuffer:
    """ãƒãƒ«ãƒãƒ¬ãƒ™ãƒ«ã®éŸ³å£°ãƒãƒƒãƒ•ã‚¡ç®¡ç†"""
    def __init__(self, sample_rate=16000):
        self.sample_rate = sample_rate
        
        # å„ãƒ¬ãƒ™ãƒ«ã®ãƒãƒƒãƒ•ã‚¡ï¼ˆç§’å˜ä½ï¼‰
        self.levels = {
            'short': {'duration': 2.0, 'overlap': 0.5},   # é«˜é€Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”¨
            'medium': {'duration': 5.0, 'overlap': 1.0},  # ãƒãƒ©ãƒ³ã‚¹å‹
            'long': {'duration': 15.0, 'overlap': 2.0}    # é«˜ç²¾åº¦ç”¨
        }
        
        # å„ãƒ¬ãƒ™ãƒ«ã®ãƒãƒƒãƒ•ã‚¡
        self.buffers = {
            level: deque(maxlen=int(config['duration'] * sample_rate * 2))
            for level, config in self.levels.items()
        }
        
        # æœ€å¾Œã«å‡¦ç†ã—ãŸã‚µãƒ³ãƒ—ãƒ«æ•°
        self.last_processed = {level: 0 for level in self.levels}
        self.total_samples = 0
        
    def add_audio(self, audio_data: np.ndarray):
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å…¨ãƒ¬ãƒ™ãƒ«ã®ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ """
        for buffer in self.buffers.values():
            buffer.extend(audio_data)
        self.total_samples += len(audio_data)
        
    def get_chunks_to_process(self) -> List[AudioChunk]:
        """å‡¦ç†ã™ã¹ããƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—"""
        chunks = []
        
        for level, config in self.levels.items():
            samples_needed = int(config['duration'] * self.sample_rate)
            samples_since_last = self.total_samples - self.last_processed[level]
            samples_step = samples_needed - int(config['overlap'] * self.sample_rate)
            
            # ã“ã®ãƒ¬ãƒ™ãƒ«ã§å‡¦ç†ãŒå¿…è¦ã‹åˆ¤å®š
            if samples_since_last >= samples_step and len(self.buffers[level]) >= samples_needed:
                # ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰å¿…è¦ãªåˆ†ã‚’å–å¾—
                audio_data = list(self.buffers[level])[-samples_needed:]
                
                chunk = AudioChunk(
                    audio=np.array(audio_data),
                    timestamp=time.time(),
                    duration=len(audio_data) / self.sample_rate,
                    level=level
                )
                chunks.append(chunk)
                self.last_processed[level] = self.total_samples
                
        return chunks

class TranscriptionWorker(mp.Process):
    """æ–‡å­—èµ·ã“ã—å°‚ç”¨ãƒ—ãƒ­ã‚»ã‚¹"""
    def __init__(self, model_name: str, input_queue: mp.Queue, output_queue: mp.Queue):
        super().__init__()
        self.model_name = model_name
        self.input_queue = input_queue
        self.output_queue = output_queue
        self.daemon = True
        
    def run(self):
        """ãƒ—ãƒ­ã‚»ã‚¹ã®ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        # ãƒ—ãƒ­ã‚»ã‚¹å†…ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ—ãƒ­ã‚»ã‚¹é–“ã§ãƒ¢ãƒ‡ãƒ«ã‚’å…±æœ‰ã§ããªã„ãŸã‚ï¼‰
        print(f"[Worker] Whisperãƒ¢ãƒ‡ãƒ« '{self.model_name}' ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        model = whisper.load_model(self.model_name)
        print("[Worker] ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")
        
        while True:
            try:
                # ã‚¿ã‚¹ã‚¯ã‚’å–å¾—
                task = self.input_queue.get(timeout=1)
                
                if task is None:  # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
                    break
                    
                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—
                start_time = time.time()
                result = model.transcribe(
                    task['audio_file'],
                    language="ja",
                    fp16=False,
                    initial_prompt=task.get('prompt', None)
                )
                transcribe_time = time.time() - start_time
                
                # çµæœã‚’è¿”ã™
                self.output_queue.put({
                    'text': result['text'].strip(),
                    'segments': result.get('segments', []),
                    'level': task['level'],
                    'timestamp': task['timestamp'],
                    'duration': task['duration'],
                    'transcribe_time': transcribe_time
                })
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                if os.path.exists(task['audio_file']):
                    os.unlink(task['audio_file'])
                    
            except queue.Empty:
                continue
            except Exception as e:
                print(f"[Worker] ã‚¨ãƒ©ãƒ¼: {e}")

class MultiLevelTranscriber:
    """ãƒãƒ«ãƒãƒ¬ãƒ™ãƒ«éŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ """
    def __init__(self, model_name="small", num_workers=2):
        self.model_name = model_name
        self.num_workers = num_workers
        self.sample_rate = 16000
        self.chunk_size = 1024
        
        # PyAudioåˆæœŸåŒ–
        self.p = pyaudio.PyAudio()
        
        # ãƒãƒ«ãƒãƒ¬ãƒ™ãƒ«ãƒãƒƒãƒ•ã‚¡
        self.buffer = MultiLevelBuffer(self.sample_rate)
        
        # ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ç”¨ã®ã‚­ãƒ¥ãƒ¼
        self.task_queue = mp.Queue(maxsize=10)
        self.result_queue = mp.Queue()
        
        # ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹
        self.workers = []
        
        # çµæœç®¡ç†
        self.results_by_level = {
            'short': deque(maxlen=10),
            'medium': deque(maxlen=5),
            'long': deque(maxlen=2)
        }
        
        self.is_running = False
        
    def start_workers(self):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã‚’èµ·å‹•"""
        for i in range(self.num_workers):
            worker = TranscriptionWorker(
                self.model_name,
                self.task_queue,
                self.result_queue
            )
            worker.start()
            self.workers.append(worker)
            
    def stop_workers(self):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã‚’åœæ­¢"""
        # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«ã‚’é€ä¿¡
        for _ in self.workers:
            self.task_queue.put(None)
            
        # ãƒ—ãƒ­ã‚»ã‚¹ã®çµ‚äº†ã‚’å¾…ã¤
        for worker in self.workers:
            worker.join(timeout=5)
            if worker.is_alive():
                worker.terminate()
                
    def save_audio_chunk(self, chunk: AudioChunk) -> str:
        """éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_filename = tmp_file.name
            
        with wave.open(tmp_filename, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(self.sample_rate)
            wf.writeframes(chunk.audio.astype(np.int16).tobytes())
            
        return tmp_filename
        
    def recording_thread(self):
        """éŒ²éŸ³ã‚¹ãƒ¬ãƒƒãƒ‰"""
        stream = self.p.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=self.sample_rate,
            input=True,
            frames_per_buffer=self.chunk_size
        )
        
        print("\nğŸ¤ ãƒãƒ«ãƒãƒ¬ãƒ™ãƒ«éŒ²éŸ³ã‚’é–‹å§‹... (Ctrl+Cã§çµ‚äº†)")
        print("ğŸ“Š ãƒ¬ãƒ™ãƒ«: short(2ç§’) / medium(5ç§’) / long(15ç§’)")
        print("-" * 80)
        
        try:
            while self.is_running:
                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚Š
                data = stream.read(self.chunk_size, exception_on_overflow=False)
                audio_chunk = np.frombuffer(data, dtype=np.int16)
                
                # ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
                self.buffer.add_audio(audio_chunk)
                
                # å‡¦ç†ã™ã¹ããƒãƒ£ãƒ³ã‚¯ã‚’ç¢ºèª
                chunks_to_process = self.buffer.get_chunks_to_process()
                
                for chunk in chunks_to_process:
                    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
                    audio_file = self.save_audio_chunk(chunk)
                    
                    # å‰ã®çµæœã‹ã‚‰æ–‡è„ˆã‚’å–å¾—
                    prompt = self.get_context_prompt(chunk.level)
                    
                    # ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
                    try:
                        self.task_queue.put_nowait({
                            'audio_file': audio_file,
                            'level': chunk.level,
                            'timestamp': chunk.timestamp,
                            'duration': chunk.duration,
                            'prompt': prompt
                        })
                        print(f"\rğŸ“¤ [{chunk.level}] ãƒãƒ£ãƒ³ã‚¯é€ä¿¡", end="", flush=True)
                    except queue.Full:
                        print(f"\nâš ï¸ ã‚­ãƒ¥ãƒ¼ãŒæº€æ¯ã§ã™ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                        os.unlink(audio_file)
                        
        finally:
            stream.stop_stream()
            stream.close()
            
    def get_context_prompt(self, level: str) -> Optional[str]:
        """æ–‡è„ˆã¨ã—ã¦ã®å‰å›ã®çµæœã‚’å–å¾—"""
        # ã‚ˆã‚Šè©³ç´°ãªãƒ¬ãƒ™ãƒ«ã®çµæœã‚’æ–‡è„ˆã¨ã—ã¦ä½¿ç”¨
        if level == 'medium' and self.results_by_level['short']:
            return self.results_by_level['short'][-1]['text'][-100:]
        elif level == 'long' and self.results_by_level['medium']:
            return self.results_by_level['medium'][-1]['text'][-200:]
        return None
        
    def result_handler_thread(self):
        """çµæœå‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰"""
        while self.is_running or not self.result_queue.empty():
            try:
                result = self.result_queue.get(timeout=1)
                
                # ãƒ¬ãƒ™ãƒ«åˆ¥ã«çµæœã‚’ä¿å­˜
                self.results_by_level[result['level']].append(result)
                
                # çµæœã‚’è¡¨ç¤º
                self.display_result(result)
                
            except queue.Empty:
                continue
                
    def display_result(self, result):
        """çµæœã‚’è¡¨ç¤º"""
        level_emoji = {
            'short': 'ğŸƒ',  # é€Ÿå ±
            'medium': 'ğŸš¶', # æ¨™æº–
            'long': 'ğŸ¯'    # ç¢ºå®š
        }
        
        emoji = level_emoji.get(result['level'], 'â“')
        speed = result['duration'] / result['transcribe_time']
        
        print(f"\n{emoji} [{result['level']:6}] {result['text']}")
        print(f"   éŸ³å£°: {result['duration']:.1f}ç§’ / å‡¦ç†: {result['transcribe_time']:.1f}ç§’ (é€Ÿåº¦: {speed:.1f}å€)")
        
        # longãƒ¬ãƒ™ãƒ«ã®å ´åˆã€å‰ã®ãƒ¬ãƒ™ãƒ«ã¨ã®å·®åˆ†ã‚’è¡¨ç¤º
        if result['level'] == 'long' and self.results_by_level['medium']:
            print("   ğŸ“ˆ ç²¾åº¦å‘ä¸Š: ã‚ˆã‚Šé•·ã„æ–‡è„ˆã§å†èªè­˜ã—ã¾ã—ãŸ")
            
        print("-" * 80)
        
    def run(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        self.is_running = True
        
        # ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã‚’èµ·å‹•
        self.start_workers()
        
        # éŒ²éŸ³ã‚¹ãƒ¬ãƒƒãƒ‰
        record_thread = threading.Thread(target=self.recording_thread)
        record_thread.daemon = True
        record_thread.start()
        
        # çµæœå‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰
        result_thread = threading.Thread(target=self.result_handler_thread)
        result_thread.daemon = True
        result_thread.start()
        
        try:
            while True:
                time.sleep(0.1)
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ çµ‚äº†å‡¦ç†ä¸­...")
            self.is_running = False
            
            # ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚’å¾…ã¤
            record_thread.join(timeout=2)
            result_thread.join(timeout=5)
            
            # ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã‚’åœæ­¢
            self.stop_workers()
            
            print("âœ… çµ‚äº†ã—ã¾ã—ãŸ")
            
        finally:
            self.p.terminate()

def main():
    print("=== Whisper ãƒãƒ«ãƒãƒ¬ãƒ™ãƒ«éŸ³å£°èªè­˜ ===")
    print("è¤‡æ•°ã®æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ã§ä¸¦åˆ—èªè­˜ã‚’è¡Œã„ã¾ã™")
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    model_name = "small"
    num_workers = 2  # ä¸¦åˆ—å‡¦ç†æ•°
    
    print(f"\nè¨­å®š:")
    print(f"- ãƒ¢ãƒ‡ãƒ«: {model_name}")
    print(f"- ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {num_workers}")
    print(f"- ãƒ¬ãƒ™ãƒ«: short(2ç§’) / medium(5ç§’) / long(15ç§’)")
    
    # ãƒãƒ«ãƒãƒ¬ãƒ™ãƒ«èªè­˜ã‚’é–‹å§‹
    transcriber = MultiLevelTranscriber(
        model_name=model_name,
        num_workers=num_workers
    )
    
    transcriber.run()

if __name__ == "__main__":
    main()