#!/usr/bin/env python3
import whisper
import pyaudio
import numpy as np
import wave
import tempfile
import os
import time
import threading
import queue
import multiprocessing as mp
from collections import deque
from dataclasses import dataclass
from typing import List, Dict, Optional, Tuple
import sys
import signal

# ANSIã‚«ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰
class Colors:
    SHORT = '\033[96m'    # ã‚·ã‚¢ãƒ³
    MEDIUM = '\033[93m'   # é»„è‰²
    LONG = '\033[92m'     # ç·‘
    ULTRA = '\033[95m'    # ãƒã‚¼ãƒ³ã‚¿
    RESET = '\033[0m'
    GRAY = '\033[90m'

@dataclass
class AudioChunk:
    """éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    audio: np.ndarray
    timestamp: float
    start_time: float
    end_time: float
    duration: float
    level: str
    rms: float

class ContinuousRecorder:
    """é€£ç¶šéŒ²éŸ³ãƒãƒƒãƒ•ã‚¡ï¼ˆæœ€å¤§2åˆ†ä¿æŒï¼‰"""
    def __init__(self, sample_rate=16000, max_duration=120):
        self.sample_rate = sample_rate
        self.max_duration = max_duration
        self.max_samples = int(max_duration * sample_rate)
        self.buffer = deque(maxlen=self.max_samples)
        self.start_timestamp = time.time()
        self.silence_start = None
        self.silence_threshold = 300
        self.silence_duration = 2.0  # 2ç§’ã®ç„¡éŸ³ã§åŒºåˆ‡ã‚Š
        self.recording_start_time = 0  # éŒ²éŸ³é–‹å§‹ã‹ã‚‰ã®çµŒéæ™‚é–“
        
    def add_audio(self, audio_data: np.ndarray) -> Optional[Tuple[np.ndarray, float, float]]:
        """éŸ³å£°ã‚’è¿½åŠ ã—ã€é•·ã„ç„¡éŸ³ãŒã‚ã‚Œã°åŒºåˆ‡ã‚Šã‚’è¿”ã™"""
        self.buffer.extend(audio_data)
        
        # RMSè¨ˆç®—
        rms = np.sqrt(np.mean(audio_data.astype(np.float32)**2))
        
        # ç„¡éŸ³æ¤œå‡º
        if rms < self.silence_threshold:
            if self.silence_start is None:
                self.silence_start = time.time()
            elif time.time() - self.silence_start > self.silence_duration:
                # é•·ã„ç„¡éŸ³ã‚’æ¤œå‡º - å…¨ä½“ã‚’è¿”ã™
                if len(self.buffer) > self.sample_rate * 5:  # 5ç§’ä»¥ä¸Šã‚ã‚‹å ´åˆ
                    audio_array = np.array(self.buffer)
                    duration = len(audio_array) / self.sample_rate
                    start_time = self.recording_start_time
                    result = (audio_array, start_time, duration)
                    # ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
                    self.buffer.clear()
                    self.recording_start_time += duration
                    self.silence_start = None
                    return result
        else:
            self.silence_start = None
            
        return None
    
    def get_buffer_info(self) -> Dict[str, float]:
        """ãƒãƒƒãƒ•ã‚¡æƒ…å ±ã‚’å–å¾—"""
        current_duration = len(self.buffer) / self.sample_rate
        memory_mb = len(self.buffer) * 2 / (1024 * 1024)  # 16bit = 2bytes
        return {
            'duration': current_duration,
            'memory_mb': memory_mb,
            'usage_percent': (current_duration / self.max_duration) * 100
        }

class MultiLevelBuffer:
    """æ”¹è‰¯ç‰ˆãƒãƒ«ãƒãƒ¬ãƒ™ãƒ«ãƒãƒƒãƒ•ã‚¡"""
    def __init__(self, sample_rate=16000):
        self.sample_rate = sample_rate
        self.recording_start = time.time()
        
        # å„ãƒ¬ãƒ™ãƒ«ã®è¨­å®š
        self.levels = {
            'short': {
                'duration': 3.0,
                'overlap': 1.0,
                'min_speech_ratio': 0.2
            },
            'medium': {
                'duration': 8.0,
                'overlap': 2.0,
                'min_speech_ratio': 0.15
            },
            'long': {
                'duration': 20.0,
                'overlap': 5.0,
                'min_speech_ratio': 0.1
            }
        }
        
        self.buffers = {
            level: deque(maxlen=int(config['duration'] * sample_rate * 2))
            for level, config in self.levels.items()
        }
        
        self.last_processed = {level: 0 for level in self.levels}
        self.total_samples = 0
        self.processed_texts = {}  # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã”ã¨ã®èªè­˜çµæœã‚’ä¿å­˜
        self.segment_cache = {}  # ãƒ¬ãƒ™ãƒ«åˆ¥ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’ä¿å­˜
        
    def add_audio(self, audio_data: np.ndarray):
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ """
        for buffer in self.buffers.values():
            buffer.extend(audio_data)
        self.total_samples += len(audio_data)
        
    def get_chunks_to_process(self) -> List[AudioChunk]:
        """å‡¦ç†ã™ã¹ããƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—"""
        chunks = []
        current_time = time.time()
        
        for level, config in self.levels.items():
            samples_needed = int(config['duration'] * self.sample_rate)
            samples_since_last = self.total_samples - self.last_processed[level]
            samples_step = samples_needed - int(config['overlap'] * self.sample_rate)
            
            if samples_since_last >= samples_step and len(self.buffers[level]) >= samples_needed:
                audio_data = np.array(list(self.buffers[level])[-samples_needed:])
                
                # éŸ³å£°åˆ†æ
                rms = np.sqrt(np.mean(audio_data.astype(np.float32)**2))
                
                # é–‹å§‹ãƒ»çµ‚äº†æ™‚åˆ»ã‚’è¨ˆç®—
                end_time = (self.total_samples / self.sample_rate)
                start_time = end_time - config['duration']
                
                if rms > 200:  # æœ€å°é–¾å€¤
                    chunk = AudioChunk(
                        audio=audio_data,
                        timestamp=current_time,
                        start_time=start_time,
                        end_time=end_time,
                        duration=config['duration'],
                        level=level,
                        rms=rms
                    )
                    chunks.append(chunk)
                    
                self.last_processed[level] = self.total_samples
                
        return chunks
    
    def get_buffer_info(self) -> Dict[str, Dict[str, float]]:
        """å„ãƒ¬ãƒ™ãƒ«ã®ãƒãƒƒãƒ•ã‚¡æƒ…å ±"""
        info = {}
        for level, buffer in self.buffers.items():
            duration = len(buffer) / self.sample_rate
            memory_kb = len(buffer) * 2 / 1024
            info[level] = {
                'duration': duration,
                'memory_kb': memory_kb
            }
        return info

class TranscriptionWorker(mp.Process):
    """æ–‡å­—èµ·ã“ã—ãƒ¯ãƒ¼ã‚«ãƒ¼"""
    def __init__(self, model_name: str, input_queue: mp.Queue, output_queue: mp.Queue):
        super().__init__()
        self.model_name = model_name
        self.input_queue = input_queue
        self.output_queue = output_queue
        self.daemon = True
        self.shutdown = mp.Event()
        
    def run(self):
        """ãƒ—ãƒ­ã‚»ã‚¹ã®ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ã‚’ç„¡åŠ¹åŒ–ï¼ˆãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã®ã¿ã§å‡¦ç†ï¼‰
        signal.signal(signal.SIGINT, signal.SIG_IGN)
        
        print(f"{Colors.GRAY}[Worker-{os.getpid()}] ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­...{Colors.RESET}")
        model = whisper.load_model(self.model_name)
        print(f"{Colors.GRAY}[Worker-{os.getpid()}] æº–å‚™å®Œäº†{Colors.RESET}")
        
        while not self.shutdown.is_set():
            try:
                task = self.input_queue.get(timeout=0.5)
                
                if task is None:
                    break
                    
                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—
                start_time = time.time()
                
                options = {
                    'language': 'ja',
                    'fp16': False,
                    'temperature': 0.0,
                    'compression_ratio_threshold': 2.0,  # ã‚ˆã‚Šå³ã—ã
                    'logprob_threshold': -1.0,
                    'no_speech_threshold': 0.7,  # ã‚ˆã‚Šå³ã—ã
                    'condition_on_previous_text': False  # å‰ã®æ–‡è„ˆã®å½±éŸ¿ã‚’æ¸›ã‚‰ã™
                }
                
                result = model.transcribe(task['audio_file'], **options)
                transcribe_time = time.time() - start_time
                
                # ãƒ†ã‚­ã‚¹ãƒˆã®å¾Œå‡¦ç†
                text = result['text'].strip()
                
                # ç¹°ã‚Šè¿”ã—ã®æ¤œå‡ºã¨é™¤å»
                if text:
                    text = self.remove_repetitions(text)
                    
                # åœ§ç¸®ç‡ãŒé«˜ã™ãã‚‹å ´åˆã¯ç„¡åŠ¹
                if result.get('compression_ratio', 0) > 2.0:
                    text = ""
                    
                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚‚å‡¦ç†
                segments = []
                if task['level'] in ['long', 'ultra'] and result.get('segments'):
                    for seg in result['segments']:
                        if seg.get('no_speech_prob', 0) < 0.7:  # éŸ³å£°ãŒã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ã„
                            segments.append({
                                'start': task['start_time'] + seg['start'],
                                'end': task['start_time'] + seg['end'],
                                'text': seg['text'].strip()
                            })
                
                # çµæœã‚’è¿”ã™
                self.output_queue.put({
                    'text': text,
                    'segments': segments,
                    'level': task['level'],
                    'start_time': task['start_time'],
                    'end_time': task['end_time'],
                    'duration': task['duration'],
                    'transcribe_time': transcribe_time,
                    'rms': task['rms']
                })
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                if os.path.exists(task['audio_file']):
                    os.unlink(task['audio_file'])
                    
            except queue.Empty:
                continue
            except Exception as e:
                if not self.shutdown.is_set():
                    print(f"\n{Colors.GRAY}[Worker] ã‚¨ãƒ©ãƒ¼: {e}{Colors.RESET}")
    
    def remove_repetitions(self, text: str) -> str:
        """ç¹°ã‚Šè¿”ã—ã‚’é™¤å»"""
        # åŒã˜ãƒ•ãƒ¬ãƒ¼ã‚ºã®ç¹°ã‚Šè¿”ã—ã‚’æ¤œå‡º
        words = text.split()
        if len(words) < 10:
            return text
            
        # ç¹°ã‚Šè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
        for pattern_len in range(2, min(10, len(words) // 2)):
            pattern = words[:pattern_len]
            is_repetition = True
            
            for i in range(pattern_len, len(words), pattern_len):
                if words[i:i+pattern_len] != pattern[:min(pattern_len, len(words)-i)]:
                    is_repetition = False
                    break
                    
            if is_repetition:
                return ' '.join(pattern)
                
        return text
    
    def stop(self):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åœæ­¢"""
        self.shutdown.set()

class AdvancedTranscriber:
    """é«˜åº¦ãªéŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ """
    def __init__(self, model_name="small", num_workers=2):
        self.model_name = model_name
        self.num_workers = num_workers
        self.sample_rate = 16000
        self.chunk_size = 1024
        
        # PyAudioåˆæœŸåŒ–
        self.p = pyaudio.PyAudio()
        
        # ãƒãƒƒãƒ•ã‚¡
        self.multilevel_buffer = MultiLevelBuffer(self.sample_rate)
        self.continuous_recorder = ContinuousRecorder(self.sample_rate)
        
        # ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹
        self.task_queue = mp.Queue(maxsize=10)
        self.result_queue = mp.Queue()
        self.workers = []
        
        # çµæœç®¡ç†
        self.all_results = []
        self.is_running = False
        
    def start_workers(self):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã‚’èµ·å‹•"""
        for i in range(self.num_workers):
            worker = TranscriptionWorker(
                self.model_name,
                self.task_queue,
                self.result_queue
            )
            worker.start()
            self.workers.append(worker)
            
    def stop_workers(self):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã‚’åœæ­¢"""
        # åœæ­¢ã‚·ã‚°ãƒŠãƒ«ã‚’é€ä¿¡
        for worker in self.workers:
            if hasattr(worker, 'stop'):
                worker.stop()
        
        # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«ã‚’é€ä¿¡
        for _ in self.workers:
            try:
                self.task_queue.put(None, timeout=1)
            except:
                pass
                
        # ãƒ—ãƒ­ã‚»ã‚¹ã®çµ‚äº†ã‚’å¾…ã¤
        for worker in self.workers:
            worker.join(timeout=3)
            if worker.is_alive():
                worker.terminate()
                worker.join(timeout=1)
                
    def save_audio_chunk(self, chunk: AudioChunk) -> str:
        """éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜"""
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_filename = tmp_file.name
            
        with wave.open(tmp_filename, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(self.sample_rate)
            wf.writeframes(chunk.audio.astype(np.int16).tobytes())
            
        return tmp_filename
        
    def recording_thread(self):
        """éŒ²éŸ³ã‚¹ãƒ¬ãƒƒãƒ‰"""
        stream = self.p.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=self.sample_rate,
            input=True,
            frames_per_buffer=self.chunk_size
        )
        
        print(f"\nğŸ¤ é«˜åº¦ãªéŸ³å£°èªè­˜ã‚’é–‹å§‹... (Ctrl+Cã§çµ‚äº†)")
        print(f"ğŸ“Š ãƒ¬ãƒ™ãƒ«: {Colors.SHORT}â–  short(3s){Colors.RESET} / {Colors.MEDIUM}â–  medium(8s){Colors.RESET} / {Colors.LONG}â–  long(20s){Colors.RESET} / {Colors.ULTRA}â–  ultra(ç„¡éŸ³åŒºåˆ‡ã‚Š){Colors.RESET}")
        print("-" * 100)
        
        try:
            while self.is_running:
                data = stream.read(self.chunk_size, exception_on_overflow=False)
                audio_chunk = np.frombuffer(data, dtype=np.int16)
                
                # ä¸¡æ–¹ã®ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
                self.multilevel_buffer.add_audio(audio_chunk)
                ultra_result = self.continuous_recorder.add_audio(audio_chunk)
                
                # è¶…é•·æœŸéŒ²éŸ³ã®å‡¦ç†
                if ultra_result:
                    audio_array, start_time, duration = ultra_result
                    print(f"\n{Colors.ULTRA}ğŸ¯ é•·æœŸéŒ²éŸ³æ¤œå‡ºï¼ ({duration:.1f}ç§’ã®éŒ²éŸ³ã‚’å‡¦ç†){Colors.RESET}")
                    
                    # Ultraãƒ¬ãƒ™ãƒ«ã¨ã—ã¦å‡¦ç†
                    chunk = AudioChunk(
                        audio=audio_array,
                        timestamp=time.time(),
                        start_time=start_time,
                        end_time=start_time + duration,
                        duration=duration,
                        level='ultra',
                        rms=np.sqrt(np.mean(audio_array.astype(np.float32)**2))
                    )
                    
                    audio_file = self.save_audio_chunk(chunk)
                    try:
                        self.task_queue.put_nowait({
                            'audio_file': audio_file,
                            'level': 'ultra',
                            'start_time': start_time,
                            'end_time': start_time + duration,
                            'duration': duration,
                            'rms': chunk.rms
                        })
                    except queue.Full:
                        os.unlink(audio_file)
                
                # é€šå¸¸ã®ãƒãƒ«ãƒãƒ¬ãƒ™ãƒ«å‡¦ç†
                chunks_to_process = self.multilevel_buffer.get_chunks_to_process()
                
                for chunk in chunks_to_process:
                    audio_file = self.save_audio_chunk(chunk)
                    
                    try:
                        self.task_queue.put_nowait({
                            'audio_file': audio_file,
                            'level': chunk.level,
                            'start_time': chunk.start_time,
                            'end_time': chunk.end_time,
                            'duration': chunk.duration,
                            'rms': chunk.rms
                        })
                    except queue.Full:
                        os.unlink(audio_file)
                        
                # ãƒãƒƒãƒ•ã‚¡æƒ…å ±ã‚’å®šæœŸçš„ã«æ›´æ–°ï¼ˆ1ç§’ã”ã¨ï¼‰
                if int(time.time()) % 1 == 0:
                    self.update_status_line()
                        
        except Exception as e:
            if self.is_running:
                print(f"\néŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            stream.stop_stream()
            stream.close()
            
    def update_status_line(self):
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ©ã‚¤ãƒ³ã‚’æ›´æ–°"""
        ml_info = self.multilevel_buffer.get_buffer_info()
        cont_info = self.continuous_recorder.get_buffer_info()
        
        status = f"\rğŸ“Š ãƒãƒƒãƒ•ã‚¡: "
        for level, info in ml_info.items():
            status += f"{level[:1]}:{info['memory_kb']:.0f}KB "
        status += f"| é€£ç¶š:{cont_info['memory_mb']:.1f}MB({cont_info['usage_percent']:.0f}%) "
        
        print(status, end="", flush=True)
            
    def result_handler_thread(self):
        """çµæœå‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰"""
        while self.is_running or not self.result_queue.empty():
            try:
                result = self.result_queue.get(timeout=0.5)
                
                if result['text']:
                    self.all_results.append(result)
                    self.display_result(result)
                    
                    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                    if result['segments']:
                        self.multilevel_buffer.segment_cache[result['level']] = result['segments']
                    
            except queue.Empty:
                continue
            except Exception as e:
                if self.is_running:
                    print(f"\nçµæœå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                
    def display_result(self, result):
        """çµæœã‚’è¡¨ç¤ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        # ãƒ¬ãƒ™ãƒ«ã”ã¨ã®è‰²ã¨ã‚¢ã‚¤ã‚³ãƒ³
        level_config = {
            'short': (Colors.SHORT, 'â—'),
            'medium': (Colors.MEDIUM, 'â—†'),
            'long': (Colors.LONG, 'â– '),
            'ultra': (Colors.ULTRA, 'â˜…')
        }
        
        color, icon = level_config.get(result['level'], (Colors.RESET, '?'))
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆã¯è¤‡æ•°è¡Œã§è¡¨ç¤º
        if result['segments'] and len(result['segments']) > 1:
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
            meta = f"{icon} [{result['start_time']:6.1f}s-{result['end_time']:6.1f}s] {result['duration']:4.1f}s/{result['transcribe_time']:3.1f}s"
            print(f"\n{meta} | {color}[ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè¡¨ç¤º]{Colors.RESET}")
            
            # å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’è¡¨ç¤º
            for seg in result['segments']:
                if seg['text']:
                    seg_time = f"  [{seg['start']:6.1f}s-{seg['end']:6.1f}s]"
                    print(f"{seg_time} {color}{seg['text']}{Colors.RESET}")
        else:
            # é€šå¸¸ã®1è¡Œè¡¨ç¤º
            timestamp = f"[{result['start_time']:6.1f}s-{result['end_time']:6.1f}s]"
            meta = f"{icon} {timestamp} {result['duration']:4.1f}s/{result['transcribe_time']:3.1f}s"
            text = f"{color}{result['text']}{Colors.RESET}"
            print(f"\n{meta} | {text}")
        
    def run(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        self.is_running = True
        
        self.start_workers()
        
        record_thread = threading.Thread(target=self.recording_thread)
        record_thread.daemon = True
        record_thread.start()
        
        result_thread = threading.Thread(target=self.result_handler_thread)
        result_thread.daemon = True
        result_thread.start()
        
        try:
            while True:
                time.sleep(0.1)
        except KeyboardInterrupt:
            print(f"\n\n{Colors.GRAY}ğŸ‘‹ çµ‚äº†å‡¦ç†ä¸­...{Colors.RESET}")
            self.is_running = False
            
            # ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚’å¾…ã¤
            record_thread.join(timeout=2)
            result_thread.join(timeout=3)
            
            # ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’åœæ­¢
            self.stop_workers()
            
            print(f"{Colors.GRAY}âœ… çµ‚äº†ã—ã¾ã—ãŸ{Colors.RESET}")
            
        finally:
            self.p.terminate()

def main():
    print("=== é«˜åº¦ãªéŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæœ€çµ‚ç‰ˆï¼‰===")
    
    model_name = "small"
    num_workers = 2
    
    print(f"è¨­å®š: ãƒ¢ãƒ‡ãƒ«={model_name}, ãƒ¯ãƒ¼ã‚«ãƒ¼={num_workers}")
    
    transcriber = AdvancedTranscriber(
        model_name=model_name,
        num_workers=num_workers
    )
    
    transcriber.run()

if __name__ == "__main__":
    main()