#!/usr/bin/env python3
"""
å®Ÿç”¨çš„ãªé€£ç¶šã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º
- ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°æ©Ÿèƒ½
- æ¤œå‡ºå‰å¾Œã®éŸ³å£°ä¿å­˜
- Whisperã¨ã®é€£æºæº–å‚™
"""

import sounddevice as sd
import numpy as np
from openwakeword.model import Model
import time
from collections import deque
import threading
import queue
from datetime import datetime
import os

class ContinuousWakeWordDetector:
    def __init__(self, 
                 wake_word="alexa",
                 threshold=0.5,
                 pre_buffer_sec=1.0,
                 post_buffer_sec=2.0):
        """
        Args:
            wake_word: æ¤œå‡ºã™ã‚‹ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰
            threshold: æ¤œå‡ºé–¾å€¤
            pre_buffer_sec: ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºå‰ã®éŸ³å£°ãƒãƒƒãƒ•ã‚¡ï¼ˆç§’ï¼‰
            post_buffer_sec: ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºå¾Œã®éŸ³å£°éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
        """
        self.wake_word = wake_word
        self.threshold = threshold
        self.pre_buffer_sec = pre_buffer_sec
        self.post_buffer_sec = post_buffer_sec
        
        # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
        print(f"ãƒ¢ãƒ‡ãƒ« '{wake_word}' ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        self.model = Model(wakeword_models=[wake_word], inference_framework="onnx")
        print("âœ“ ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«æˆåŠŸã—ã¾ã—ãŸ")
        
        # éŸ³å£°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.sample_rate = 16000
        self.frame_length = 1280  # 80ms
        self.block_size = 320     # 20ms (ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·)
        
        # ãƒãƒƒãƒ•ã‚¡
        pre_buffer_samples = int(self.sample_rate * self.pre_buffer_sec)
        self.pre_buffer = deque(maxlen=pre_buffer_samples)
        self.audio_queue = queue.Queue()
        
        # çŠ¶æ…‹ç®¡ç†
        self.is_listening = True
        self.is_recording_command = False
        self.command_buffer = []
        self.command_start_time = 0
        
        # æ¤œå‡ºå±¥æ­´
        self.detection_history = []
        
    def audio_callback(self, indata, frames, time, status):
        """éŸ³å£°å…¥åŠ›ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        if status:
            print(f"ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¨ãƒ©ãƒ¼: {status}")
        
        # float32 -> int16
        audio_int16 = (indata[:, 0] * 32767).astype(np.int16)
        
        # ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ï¼ˆå‡¦ç†ã¯åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰
        self.audio_queue.put(audio_int16)
    
    def process_audio_stream(self):
        """éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ å‡¦ç†ï¼ˆåˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰"""
        frame_buffer = np.array([], dtype=np.int16)
        
        while self.is_listening:
            try:
                # ã‚­ãƒ¥ãƒ¼ã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                audio_chunk = self.audio_queue.get(timeout=0.1)
                
                # ãƒ—ãƒªãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ ï¼ˆå¸¸æ™‚ï¼‰
                self.pre_buffer.extend(audio_chunk)
                
                # ã‚³ãƒãƒ³ãƒ‰éŒ²éŸ³ä¸­ã®å ´åˆ
                if self.is_recording_command:
                    self.command_buffer.extend(audio_chunk)
                    
                    # éŒ²éŸ³æ™‚é–“ãƒã‚§ãƒƒã‚¯
                    elapsed = time.time() - self.command_start_time
                    if elapsed >= self.post_buffer_sec:
                        self.process_command()
                        continue
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
                frame_buffer = np.append(frame_buffer, audio_chunk)
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã§å‡¦ç†
                while len(frame_buffer) >= self.frame_length:
                    frame = frame_buffer[:self.frame_length]
                    frame_buffer = frame_buffer[self.frame_length:]
                    
                    # ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º
                    if not self.is_recording_command:
                        self.detect_wake_word(frame)
                        
            except queue.Empty:
                continue
            except Exception as e:
                print(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def detect_wake_word(self, frame):
        """ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º"""
        # æ¨è«–
        prediction = self.model.predict(frame)
        score = prediction.get(self.wake_word, 0)
        
        # ã‚¹ã‚³ã‚¢è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰
        if score > 0.1:
            bar = 'â–ˆ' * int(score * 20)
            print(f"\r[{bar:<20}] {score:.3f}", end="", flush=True)
        
        # é–¾å€¤ãƒã‚§ãƒƒã‚¯
        if score > self.threshold:
            self.on_wake_word_detected(score)
    
    def on_wake_word_detected(self, score):
        """ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºæ™‚ã®å‡¦ç†"""
        print(f"\n\n{'='*50}")
        print(f"ğŸ¯ ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ '{self.wake_word}' ã‚’æ¤œå‡ºï¼")
        print(f"ã‚¹ã‚³ã‚¢: {score:.3f}")
        print(f"æ™‚åˆ»: {datetime.now().strftime('%H:%M:%S')}")
        print(f"{'='*50}")
        print(f"\nğŸ“¢ éŸ³å£°ã‚³ãƒãƒ³ãƒ‰ã‚’ã©ã†ã... ({self.post_buffer_sec}ç§’é–“éŒ²éŸ³)")
        
        # ã‚³ãƒãƒ³ãƒ‰éŒ²éŸ³é–‹å§‹
        self.is_recording_command = True
        self.command_start_time = time.time()
        
        # ãƒ—ãƒªãƒãƒƒãƒ•ã‚¡ã®å†…å®¹ã‚’ã‚³ãƒãƒ³ãƒ‰ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
        self.command_buffer = list(self.pre_buffer)
        
        # æ¤œå‡ºå±¥æ­´ã«è¿½åŠ 
        self.detection_history.append({
            'timestamp': datetime.now(),
            'score': score
        })
    
    def process_command(self):
        """éŒ²éŸ³ã•ã‚ŒãŸã‚³ãƒãƒ³ãƒ‰ã‚’å‡¦ç†"""
        self.is_recording_command = False
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ numpy é…åˆ—ã«å¤‰æ›
        audio_data = np.array(self.command_buffer, dtype=np.int16)
        
        print(f"\nâœ… éŒ²éŸ³å®Œäº†ï¼")
        print(f"éŒ²éŸ³æ™‚é–“: {len(audio_data) / self.sample_rate:.1f}ç§’")
        print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(audio_data)}")
        
        # ã“ã“ã§Whisperã«ã‚ˆã‚‹éŸ³å£°èªè­˜ã‚’å®Ÿè¡Œ
        print("\nğŸ¤– éŸ³å£°èªè­˜ã‚’å®Ÿè¡Œ... (Whisperã¨ã®é€£æºéƒ¨åˆ†)")
        print(">>> ã“ã“ã§ whisper.transcribe(audio_data) ã‚’å®Ÿè¡Œ")
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        if os.environ.get('SAVE_AUDIO', '').lower() == 'true':
            self.save_audio(audio_data)
        
        # ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
        self.command_buffer = []
        
        print(f"\n{'='*50}")
        print("å†ã³ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ã‚’å¾…ã£ã¦ã„ã¾ã™...\n")
    
    def save_audio(self, audio_data):
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"wake_command_{timestamp}.wav"
        
        import wave
        with wave.open(filename, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)  # 16bit
            wf.setframerate(self.sample_rate)
            wf.writeframes(audio_data.tobytes())
        
        print(f"ğŸ“ éŸ³å£°ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
    
    def show_statistics(self):
        """çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º"""
        print("\nğŸ“Š æ¤œå‡ºçµ±è¨ˆ:")
        print(f"ç·æ¤œå‡ºå›æ•°: {len(self.detection_history)}")
        
        if self.detection_history:
            avg_score = np.mean([d['score'] for d in self.detection_history])
            print(f"å¹³å‡ã‚¹ã‚³ã‚¢: {avg_score:.3f}")
            
            # æœ€è¿‘ã®5ä»¶
            print("\næœ€è¿‘ã®æ¤œå‡º:")
            for detection in self.detection_history[-5:]:
                print(f"  - {detection['timestamp'].strftime('%H:%M:%S')} "
                      f"(ã‚¹ã‚³ã‚¢: {detection['score']:.3f})")
    
    def run(self):
        """æ¤œå‡ºé–‹å§‹"""
        print(f"\n{'='*60}")
        print("ğŸ’« é€£ç¶šã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ")
        print(f"{'='*60}")
        print(f"ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰: '{self.wake_word}'")
        print(f"æ¤œå‡ºé–¾å€¤: {self.threshold}")
        print(f"ãƒ—ãƒªãƒãƒƒãƒ•ã‚¡: {self.pre_buffer_sec}ç§’")
        print(f"éŒ²éŸ³æ™‚é–“: {self.post_buffer_sec}ç§’")
        print(f"{'='*60}")
        print("\nã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ã‚’è©±ã—ã¦ãã ã•ã„... (Ctrl+Cã§çµ‚äº†)")
        print("ãƒ’ãƒ³ãƒˆ: éŸ³å£°ä¿å­˜ã‚’æœ‰åŠ¹ã«ã™ã‚‹å ´åˆã¯ SAVE_AUDIO=true ã‚’è¨­å®š\n")
        
        # å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        process_thread = threading.Thread(target=self.process_audio_stream)
        process_thread.daemon = True
        process_thread.start()
        
        try:
            # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹
            with sd.InputStream(
                callback=self.audio_callback,
                channels=1,
                samplerate=self.sample_rate,
                blocksize=self.block_size
            ):
                while True:
                    time.sleep(0.1)
                    
        except KeyboardInterrupt:
            self.is_listening = False
            print("\n\næ¤œå‡ºã‚’çµ‚äº†ã—ã¾ã™...")
            self.show_statistics()
            print("\nğŸ‘‹ ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="é€£ç¶šã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º"
    )
    parser.add_argument(
        "--model", "-m",
        default="alexa",
        help="ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ãƒ¢ãƒ‡ãƒ«"
    )
    parser.add_argument(
        "--threshold", "-t",
        type=float,
        default=0.5,
        help="æ¤œå‡ºé–¾å€¤"
    )
    parser.add_argument(
        "--pre-buffer", "-p",
        type=float,
        default=1.0,
        help="ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰å‰ã®ãƒãƒƒãƒ•ã‚¡æ™‚é–“ï¼ˆç§’ï¼‰"
    )
    parser.add_argument(
        "--post-buffer", "-o",
        type=float,
        default=3.0,
        help="ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰å¾Œã®éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰"
    )
    
    args = parser.parse_args()
    
    detector = ContinuousWakeWordDetector(
        wake_word=args.model,
        threshold=args.threshold,
        pre_buffer_sec=args.pre_buffer,
        post_buffer_sec=args.post_buffer
    )
    
    detector.run()

if __name__ == "__main__":
    main()